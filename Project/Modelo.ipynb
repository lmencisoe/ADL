{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1PFEOIcZ+1Hb3YZBQNghK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmencisoe/ADL/blob/main/Project/Modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9n87lu-K9Jt"
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from pandas_profiling import ProfileReport\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.models import Sequential\n",
        "from xgboost import plot_importance\n",
        "from keras.layers import Dropout, Flatten, Dense, Input, Rescaling, Lambda, MaxPooling2D, Conv2D, AveragePooling2D\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection  import GridSearchCV\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "import statistics\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FBpnSmsVK-dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df3 = pd.read_csv(\"/content/drive/MyDrive/Proyecto_ADL/data_modelo.csv\",sep=\";\")\n",
        "base_total_max = pd.read_csv(\"/content/drive/MyDrive/Proyecto_ADL/equipos.csv\",sep=\";\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "XDSuOhoLLxBS",
        "outputId": "bcb890d9-579c-4871-8bca-0ebf51c12266"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35382953ff29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_df3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Proyecto_ADL/data_modelo.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_total_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Proyecto_ADL/equipos.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_base_model = new_df3.drop(columns=['team', 'team2', 'results', 'neutral_location'])\n",
        "Y_model = new_df3['results']\n",
        "Y_model"
      ],
      "metadata": {
        "id": "ljPCEIBqLtC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_base_model, Y_model, test_size=0.2, random_state=2022)"
      ],
      "metadata": {
        "id": "sbsXfaUpLtfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dict = [{'':str(x)} for x in y_train.tolist()]\n",
        "y_dict_test = [{'':str(x)} for x in y_test.tolist()]\n",
        "vec = DictVectorizer(sparse=False, dtype=int)\n",
        "M_train = vec.fit_transform(y_dict)\n",
        "M_test = vec.fit_transform(y_dict_test)"
      ],
      "metadata": {
        "id": "WADaalOMMtA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(meta, activation, n_layers, hidden_layer_1, hidden_layer_2 = None, hidden_layer_3 = None):\n",
        "    # note that meta is a special argument that will be\n",
        "    # handed a dict containing input metadata\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "    X_shape_ = meta[\"X_shape_\"]\n",
        "    dims = [hidden_layer_1, hidden_layer_2, hidden_layer_3]\n",
        "\n",
        "    model = Sequential(name=\"Red_CV\")\n",
        "    model.add(Dense(n_features_in_, input_shape=X_shape_[1:]))\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        model.add(Dense(dims[i], activation=activation))\n",
        "    \n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "FyGfSWU3Mxmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KerasClassifier(\n",
        "    get_model,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    n_layers=2,\n",
        "    hidden_layer_1=30, \n",
        "    hidden_layer_2=10,\n",
        "    hidden_layer_3=None,\n",
        "    metrics=[\"accuracy\"],\n",
        "    epochs=10,\n",
        "    activation=\"relu\"\n",
        ")\n",
        "\n",
        "clf"
      ],
      "metadata": {
        "id": "dJYHdbT6MzRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer([\n",
        "       ('encoder', OneHotEncoder(handle_unknown='ignore'),\n",
        "       make_column_selector(dtype_include=np.object)),\n",
        "       ], remainder='passthrough')\n",
        "estimators = [\n",
        "              ('encoder', ct),\n",
        "              ('clf', clf),\n",
        "              ]\n",
        "\n",
        "pipe = Pipeline(estimators)"
      ],
      "metadata": {
        "id": "awuWKXYxM1Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "NWvgiyAAM5Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict(X_train)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "9HjdI98QM6ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "9GxzseAEM8is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'): \n",
        "    params = {\n",
        "              \"clf__hidden_layer_1\": [8, 100, 10, 5],\n",
        "              \"clf__hidden_layer_2\": [8, 100, 10, 5],\n",
        "              \"clf__hidden_layer_3\": [8, 100, 10, 5],\n",
        "              \"clf__n_layers\": [1,2,3],\n",
        "              \"clf__activation\": [\"relu\", \"linear\", \"sigmoid\"],\n",
        "              \"clf__optimizer\": [\"adam\", \"sgd\"],\n",
        "              \"clf__optimizer__learning_rate\": [0.0001, 0.001, 0.1],\n",
        "              \"clf__epochs\": [10, 30, 20],\n",
        "             }\n",
        "    grid = RandomizedSearchCV(pipe, params, cv=3, scoring='neg_log_loss', n_iter=10, random_state=2022)"
      ],
      "metadata": {
        "id": "OJVYvAMRM-WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "NA596MyWM_t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "\n",
        "grid.best_params_"
      ],
      "metadata": {
        "id": "jgGMk67kNBqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_train)\n",
        "y_pred\n",
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "GF7aAIGoNDA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "y_pred\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "AlgbYcRuNImj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_new(equipo1, equipo2):\n",
        "    base1 = base_total_max[base_total_max['team'] == equipo1]\n",
        "    base2 = base_total_max[base_total_max['team'] == equipo2]\n",
        "    return base1"
      ],
      "metadata": {
        "id": "-r6RI3qTNLuA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}